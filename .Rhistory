library(here)
library(PAMpal)
myGrouping<-read.csv(here('EventTimes','ADRIFT_032_GgTimes.csv'))
myGrouping<-read.csv(here('EventTimes','ADRIFT_032_GgTimes.csv'))
myGrouping<-read.csv(here('EventTimes','ADRIFT_032_GgTimes.csv'))
as.POSIXct(myGrouping$start)
as.POSIXct(myGrouping$start,tz='UTC')
as.POSIXct(myGrouping$start,tz='UTC',format='%m/%d/%y %H:%M')
myGrouping$end<-as.POSIXct(myGrouping$end,tz='UTC',format='%m/%d/%y %H:%M')
myGrouping$start<-as.POSIXct(myGrouping$start,tz='UTC',format='%m/%d/%y %H:%M')
data <- processPgDetections(pps, mode='time',grouping=myGrouping)
#Read in event times
myGrouping<-read.csv(here('EventTimes','ADRIFT_032_GgTimes.csv'))
myGrouping$start<-as.POSIXct(myGrouping$start,tz='UTC',format='%m/%d/%y %H:%M')
myGrouping$end<-as.POSIXct(myGrouping$end,tz='UTC',format='%m/%d/%y %H:%M')
data <- processPgDetections(pps, mode='time',grouping=myGrouping)
#Read in event times
myGrouping<-read.csv(here('EventTimes','ADRIFT_032_GgTimes.csv'))
myGrouping$start<-as.POSIXct(myGrouping$start,tz='UTC',format='%m/%d/%y %H:%M')
myGrouping$end<-as.POSIXct(myGrouping$end,tz='UTC',format='%m/%d/%y %H:%M')
data <- processPgDetections(pps, mode='time',grouping=myGrouping)
myGrouping$id<-'ADRIFT_032_1'
data <- processPgDetections(pps, mode='time',grouping=myGrouping)
?processPgDetections
data <- processPgDetections(pps, mode='time',grouping=here('EventTimes','ADRIFT_032_GgTimes.csv'))
data <- processPgDetections(pps, grouping=here('EventTimes','ADRIFT_032_GgTimes.csv'))
data <- processPgDetections(pps, grouping=here('EventTimes','ADRIFT_032_GgTimes.csv'),,format='%m/%d/%y %H:%M')
data <- processPgDetections(pps, grouping=here('EventTimes','ADRIFT_032_GgTimes.csv'),format='%m/%d/%y %H:%M')
data <- processPgDetections(pps, mode='time' grouping=here('EventTimes','ADRIFT_032_GgTimes.csv'),format='%m/%d/%y %H:%M')
data <- processPgDetections(pps, mode='time', grouping=here('EventTimes','ADRIFT_032_GgTimes.csv'),format='%m/%d/%y %H:%M')
data <- processPgDetections(pps, mode='time',grouping=here('EventTimes','ADRIFT_032_GgTimes.csv',format='%m/%d/%y %H:%M'))
### Process with PAMpal ###
pps <- PAMpalSettings(db, binFolder, sr_hz='auto', filterfrom_khz=10, filterto_khz=80, winLen_sec=.0025)
# this database should be a COPY of the original because we will add events to it later
db <- paste0(baseDir,'Databases/',DriftName,' - Copy.sqlite3')
###USER-DEFINED FIELDS####
baseDir <- 'D:/Analysis/RissosGeographicVariation/'
DriftName<-'ADRIFT_032'
binFolder <- paste0(baseDir,'Binaries/',DriftName)    #Folder with binaries
# this database should be a COPY of the original because we will add events to it later
db <- paste0(baseDir,'Databases/',DriftName,' - Copy.sqlite3')
### Process with PAMpal ###
pps <- PAMpalSettings(db, binFolder, sr_hz='auto', filterfrom_khz=10, filterto_khz=80, winLen_sec=.0025)
#Read in event times
myGrouping<-read.csv(here('EventTimes','ADRIFT_032_GgTimes.csv'))
myGrouping$start<-as.POSIXct(myGrouping$start,tz='UTC',format='%m/%d/%y %H:%M')
myGrouping$end<-as.POSIXct(myGrouping$end,tz='UTC',format='%m/%d/%y %H:%M')
data <- processPgDetections(pps, mode='time',grouping=here('EventTimes','ADRIFT_032_GgTimes.csv',format='%m/%d/%y %H:%M'))
here()
data <- processPgDetections(pps, mode='time',grouping=here('EventTimes','ADRIFT_032_GgTimes.csv'),format='%m/%d/%y %H:%M')
data <- processPgDetections(pps, mode='time',grouping=here('EventTimes','ADRIFT_032_GgTimes.csv'),format='%m/%d/%y %H:%M')
#Read in event times
data <- processPgDetections(pps, mode='time',grouping=here('EventTimes','ADRIFT_032_GgTimes.csv'),
format='%m/%d/%y %H:%M',species='Gg')
#Read in event times
myGrouping<-read.csv(here('EventTimes','ADRIFT_032_GgTimes.csv'))
myGrouping$start<-as.POSIXct(myGrouping$start,tz='UTC',format='%m/%d/%y %H:%M')
myGrouping$end<-as.POSIXct(myGrouping$end,tz='UTC',format='%m/%d/%y %H:%M')
data <- processPgDetections(pps, mode='time',grouping=myGrouping)
data <- processPgDetections(pps, mode='recording')
# make sure you have Rtools installed
if(!require('devtools')) install.packages('devtools')
# install from GitHub
devtools::install_github('TaikiSan21/PAMpal')
# make sure you have Rtools installed
if(!require('devtools')) install.packages('devtools')
# install from GitHub
devtools::install_github('TaikiSan21/PAMpal')
#load packages
library(here)
library(PAMpal)
###USER-DEFINED FIELDS####
baseDir <- 'D:/Analysis/RissosGeographicVariation/'
DriftName<-'ADRIFT_032'
binFolder <- paste0(baseDir,'Binaries/',DriftName)    #Folder with binaries
# this database should be a COPY of the original because we will add events to it later
db <- paste0(baseDir,'Databases/',DriftName,' - Copy.sqlite3')
### Process with PAMpal ###
pps <- PAMpalSettings(db, binFolder, sr_hz='auto', filterfrom_khz=10, filterto_khz=80, winLen_sec=.0025)
#Read in event times
myGrouping<-read.csv(here('EventTimes','ADRIFT_032_GgTimes.csv'))
myGrouping$start<-as.POSIXct(myGrouping$start,tz='UTC',format='%m/%d/%y %H:%M')
myGrouping$end<-as.POSIXct(myGrouping$end,tz='UTC',format='%m/%d/%y %H:%M')
data <- processPgDetections(pps, mode='time',grouping=here('EventTimes','ADRIFT_032_GgTimes.csv'),format='%m/%d/%y %H:%M')
#Remove likely false positives
data<-filter(data,peak<=19)
?dplyr::filter
data <- processPgDetections(pps, mode='time',grouping=myGrouping,species="Gg",id=DriftName)
data <- processPgDetections(pps, mode='time',grouping=here('EventTimes','ADRIFT_032_GgTimes.csv'),
format='%m/%d/%y %H:%M',species='Gg',id=DriftName)
source(here('R','Matched Click Template Detector','matchTemplateFunctions.R'))
addbaseDir
baseDir
#Keep click detections from one channel
data<-filter(data, Channel==2)
#Remove likely false positives based on following features:
#peak frequency<19 kHz
data<-filter(data,peak>=19)
addTemplateEvents(db,binFolder,data)
db<-addTemplateEvents(db,binFolder,data)
db
binFolder
data
?addTemplateEvents
source("C:/Users/annes/Documents/Github/Rissos_Geographic_Variation/R/Matched Click Template Detector/matchTemplateFunctions.R")
addTemplateEvents(db,binFolder,data)
data<-markGoodEvents(data,minDets=3,maxSep=500)
data$Template<-1
addTemplateEvents(db,binFolder,data)
View(data)
?addPgEvent
addPgEvent(db,data)
View(data)
ClickData=getClickData(data)
addPgEvent(db,binaries=data@files[["binaries"]],UIDs=ClickData$UID,eventType='GgClick')
addPgEvent(db,binaries=ClickData$BinaryFile,UIDs=ClickData$UID,eventType='GgClick')
addPgEvent(db,binary = data@files[["binaries"]],UIDs=ClickData$UID,eventType='GgClick')
data<-filter(data,detectorName!='Click_Detector_1')
data<-filter(data,detectorName!='Click_Detector_0')
ClickData<-filter(Clickdata, peak>19)
#Remove likely false positives based on following features:
#peak frequency<19 kHz
ClickData<-getClickData(data)
ClickData<-filter(ClickData, peak>19)
#Add events to database
addPgEvent(db,binary = data@files[["binaries"]],UIDs=ClickData$UID,eventType='GgClick')
#load packages
library(here)
library(PAMpal)
library(PAMmisc)
library(dplyr)
###USER-DEFINED FIELDS####
baseDir <- 'D:/Analysis/RissosGeographicVariation/'
DriftID<-'ADRIFT_039'
binFolder <- paste0(baseDir,'Binaries/',DriftID)    #Folder with binaries
# this database should be a COPY of the original because we will add events to it later
db <- paste0(baseDir,'Databases/',DriftID,' - Copy.sqlite3')
#load acoustic study
data<-readRDS(paste0(baseDir,'AcousticStudies/',DriftID,'_Gg.rds'))
#Remove likely false positives based on following features:
#peak frequency<19 kHz
ClickData<-getClickData(data)
summary(ClickData$Channel)
hist(ClickData$Channel)
hist(as.numeric(ClickData$Channel))
knitr::opts_chunk$set(echo = TRUE)
# When this rmarkdown file is knit:
# FALSE means it will used saved .rds files instead of re-processing
# TRUE will run everything from scratch - this will take a long time
freshRun <- FALSE
library("easypackages")
libraries("PAMpal","PAMmisc","dplyr", "magick", "magrittr", "here")
here()
###USER-DEFINED FIELDS####
baseDir <- 'D:/Analysis/RissosGeographicVariation/'
DriftID<-'ADRIFT_039'
binFolder <- paste0(baseDir,'Binaries/',DriftID)    #Folder with binaries
# this database should be a COPY of the original because we will add events to it later
db <- paste0(baseDir,'Databases/',DriftID,' - Copy.sqlite3')
pps <- PAMpalSettings(db=db,
binaries = binFolder,
sr_hz='auto',
winLen_sec=.0025,
filterfrom_khz=10,
filterto_khz=80)
#Import known Risso's dolphin Event Times
GgTimes<-read.csv(here('EventTimes','ADRIFT_GgDetections.csv'))
GgTimes$start<-as.POSIXct(GgTimes$UTC,format='%Y-%m-%d %H:%M:%S',tz='UTC')
GgTimes$end<-as.POSIXct(GgTimes$end,format='%Y-%m-%d %H:%M:%S',tz='UTC')
DriftTimes<-filter(GgTimes,DriftName==DriftID)
DriftTimes$id<-paste0(DriftID,'_',seq(1:nrow(DriftTimes)))
#Use event times from CSV file
data <- processPgDetections(pps, mode='time',grouping=DriftTimes,
format='%m/%d/%y %H:%M',species='Gg',id=DriftID)
knitr::opts_chunk$set(echo = TRUE)
# When this rmarkdown file is knit:
# FALSE means it will used saved .rds files instead of re-processing
# TRUE will run everything from scratch - this will take a long time
freshRun <- FALSE
library("easypackages")
libraries("PAMpal","PAMmisc","dplyr",  "here")
here()
###USER-DEFINED FIELDS####
baseDir <- 'D:/Analysis/RissosGeographicVariation/'
DriftID<-'ADRIFT_039'
binFolder <- paste0(baseDir,'Binaries/',DriftID)    #Folder with binaries
# this database should be a COPY of the original because we will add events to it later
db <- paste0(baseDir,'Databases/',DriftID,' - Copy.sqlite3')
pps <- PAMpalSettings(db=db,
binaries = binFolder,
sr_hz='auto',
winLen_sec=.0025,
filterfrom_khz=10,
filterto_khz=80)
#Import known Risso's dolphin Event Times
GgTimes<-read.csv(here('EventTimes','ADRIFT_GgDetections.csv'))
GgTimes$start<-as.POSIXct(GgTimes$UTC,format='%Y-%m-%d %H:%M:%S',tz='UTC')
GgTimes$end<-as.POSIXct(GgTimes$end,format='%Y-%m-%d %H:%M:%S',tz='UTC')
DriftTimes<-filter(GgTimes,DriftName==DriftID)
DriftTimes$id<-paste0(DriftID,'_',seq(1:nrow(DriftTimes)))
#Use event times from CSV file
data <- processPgDetections(pps, mode='time',grouping=DriftTimes,
format='%m/%d/%y %H:%M',species='Gg',id=DriftID)
data<-readRDS(paste0(baseDir,'AcousticStudies/',DriftID,'_Gg.rds'))
# Double check warning messages
print(getWarnings(data)$message)
#Keep click detections from one channel (upper hydrophone = HTI-92-WB)
data<-filter(data, Channel==1)
#Omit click detectors 0 and 1
data<-filter(data,detectorName!='Click_Detector_0')
data<-filter(data,detectorName!='Click_Detector_1')
data<-filter(data, peak>15 & duration<2000)
#Add events to database
for(E in 1:nrow(DriftTimes)){
EventClicks<-filter(ClickData,eventId==DriftTimes$id[E])
addPgEvent(db,binary = data@events[[E]]@files[["binaries"]],
UIDs=EventClicks$UID,
eventType='Gg Click Event',
start=DriftTimes$start[E],
end=DriftTimes$end[E],
type='click')
}
ClickData<-getClickData(data)
#Add events to database
for(E in 1:nrow(DriftTimes)){
EventClicks<-filter(ClickData,eventId==DriftTimes$id[E])
addPgEvent(db,binary = data@events[[E]]@files[["binaries"]],
UIDs=EventClicks$UID,
eventType='Gg Click Event',
start=DriftTimes$start[E],
end=DriftTimes$end[E],
type='click')
}
