filter(!UID %in% IgnoreClicks$UID)
}
library(data.table)
CD <- as.data.table(ClickData)
setkey(CD, eventId)
uid_by_event <- CD[, .(UIDs = list(UID)), by = eventId]
uid_lookup <- setNames(uid_by_event$UIDs, uid_by_event$eventId)
DBI::dbWithTransaction(db, {
for (i in seq_len(nrow(DriftTimes))) {
id <- DriftTimes$id[i]
addPgEvent(
db,
binary    = bin_by_event[[as.character(id)]],
UIDs      = uid_lookup[[as.character(id)]],
eventType = "Gg Click Event",
start     = DriftTimes$start[i],
end       = DriftTimes$end[i],
type      = "click"
)
}
})
CD <- as.data.table(ClickData)
setkey(CD, eventId)
uid_by_event <- CD[, .(UIDs = list(UID)), by = eventId]
uid_lookup <- setNames(uid_by_event$UIDs, uid_by_event$eventId)
library(DBI)
library(RSQLite)
# open connection
con <- dbConnect(RSQLite::SQLite(), db)
dbWithTransaction(con, {
for (i in seq_len(nrow(DriftTimes))) {
id <- DriftTimes$id[i]
addPgEvent(
con,  # use connection here
binary    = bin_by_event[[as.character(id)]],
UIDs      = uid_lookup[[as.character(id)]],
eventType = "Gg Click Event",
start     = DriftTimes$start[i],
end       = DriftTimes$end[i],
type      = "click"
)
}
})
db
i
file.exists(db)
# open connection
con <- dbConnect(RSQLite::SQLite(), db)
dbWithTransaction(con, {
for (i in seq_len(nrow(DriftTimes))) {
id <- DriftTimes$id[i]
addPgEvent(
con,  # use connection here
binary    = bin_by_event[[as.character(id)]],
UIDs      = uid_lookup[[as.character(id)]],
eventType = "Gg Click Event",
start     = DriftTimes$start[i],
end       = DriftTimes$end[i],
type      = "click"
)
}
})
db
db_path <- "C:/Users/annes/Documents/Github/Rissos_Geographic_Variation/data/Databases/ADRIFT_055 - Copy.sqlite3"   # <- must be a single character string
for (i in seq_len(nrow(DriftTimes))) {
id <- DriftTimes$id[i]
addPgEvent(
db_path,  # or your original PAMpal db handle variable
binary    = bin_by_event[[as.character(id)]],
UIDs      = uid_lookup[[as.character(id)]],
eventType = "Gg Click Event",
start     = DriftTimes$start[i],
end       = DriftTimes$end[i],
type      = "click"
)
}
# fast lookup: UIDs per eventId
uid_by_event <- split(ClickData$UID, ClickData$eventId)
# if your events are already aligned 1:1 with DriftTimes rows, precompute binaries too
bin_by_event <- lapply(data@events, function(ev) ev@files[["binaries"]])
names(bin_by_event) <- DriftTimes$id   # ensure names match the ids you'll look up
db_path <- "C:/Users/annes/Documents/Github/Rissos_Geographic_Variation/data/Databases/ADRIFT_055 - Copy.sqlite3"   # <- must be a single character string
for (i in seq_len(nrow(DriftTimes))) {
id <- DriftTimes$id[i]
addPgEvent(
db_path,  # or your original PAMpal db handle variable
binary    = bin_by_event[[as.character(id)]],
UIDs      = uid_lookup[[as.character(id)]],
eventType = "Gg Click Event",
start     = DriftTimes$start[i],
end       = DriftTimes$end[i],
type      = "click"
)
}
dbDisconnect()
dbDisconnect(con)
conn =
dbDisconnect(conn)
ClickData<-getClickData(data)
#Keep subset of data for events with more than 100,000 clicks
TooBig<-ClickData %>%
group_by(eventId) %>%
summarize(TotalClicks = n()) %>%
filter(TotalClicks>100000)
#For events with large sample sizes, randomly select 80% of clicks to remove
for(b in 1:nrow(TooBig)){
set.seed(1)
KeepClicks<-ClickData %>%
filter(eventId==TooBig$eventId[b]) %>%
slice_sample(prop=0.15)
ClickData<-ClickData %>%f
filter(!UID %in% KeepClicks$UID)
}
#For events with large sample sizes, randomly select 80% of clicks to remove
for(b in 1:nrow(TooBig)){
set.seed(1)
KeepClicks<-ClickData %>%
filter(eventId==TooBig$eventId[b]) %>%
slice_sample(prop=0.15)
ClickData<-ClickData %>%
filter(!UID %in% KeepClicks$UID)
}
# fast lookup: UIDs per eventId
uid_by_event <- split(ClickData$UID, ClickData$eventId)
# if your events are already aligned 1:1 with DriftTimes rows, precompute binaries too
bin_by_event <- lapply(data@events, function(ev) ev@files[["binaries"]])
names(bin_by_event) <- DriftTimes$id   # ensure names match the ids you'll look up
db_path <- "C:/Users/annes/Documents/Github/Rissos_Geographic_Variation/data/Databases/ADRIFT_055 - Copy.sqlite3"   # <- must be a single character string
for (i in seq_len(nrow(DriftTimes))) {
id <- DriftTimes$id[i]
addPgEvent(
db_path,  # or your original PAMpal db handle variable
binary    = bin_by_event[[as.character(id)]],
UIDs      = uid_lookup[[as.character(id)]],
eventType = "Gg Click Event",
start     = DriftTimes$start[i],
end       = DriftTimes$end[i],
type      = "click"
)
}
beep()
beep()
beep()
beep()
calculateAverageSpectra(data,flim=c(0,100000),evNum=5)
knitr::opts_chunk$set(echo = TRUE)
suppressPackageStartupMessages({
library(fs)
library(stringr)
})
out_root <-  file.path(baseDir,'SpectrogramsAndSpectra')
drift_dir <- fs::path(out_root, DriftID)
dir_create(drift_dir)
if (exists("DriftTimes")) {
event_ids <- seq_len(nrow(DriftTimes))
} else if (exists("ClickData") && "eventId" %in% names(ClickData)) {
event_ids <- sort(unique(na.omit(as.integer(ClickData$eventId))))
} else {
stop("Can't determine events: need DriftTimes or ClickData$eventId.")
}
cat(sprintf("Drift %s: %s event(s)\n", DriftID, length(event_ids)))
event_names <- paste0(DriftID, "_Event_", str_pad(event_ids, 3, pad = "0"))
event_dirs  <- fs::path(drift_dir, event_names)
fs::dir_create(event_dirs)
View(TooBig)
5:6
#Loop: one call per event -> two plots auto-saved -> rename
# for (k in seq_along(event_ids)) {
for (k in 5:6) {
i      <- event_ids[k]
ev_dir <- event_dirs[k]
ev_tag <- event_names[k]
#Temp pattern with %d to capture both plots
pattern <- fs::path(ev_dir, paste0(ev_tag, "_%02d.png"))
png(filename = pattern, width = 1600, height = 1000, res = 150, bg = "white")
calculateAverageSpectra(data, flim = c(0, 100000), evNum = i)
dev.off()
#Paths for the auto-saved plots
img1 <- fs::path(ev_dir, paste0(ev_tag, "_01.png"))
img2 <- fs::path(ev_dir, paste0(ev_tag, "_02.png"))
#Desired names: Spectrogram_XXX.png and Spectrum_XXX.png
suffix <- str_pad(i, 3, pad = "0")
spg_dst  <- fs::path(ev_dir, paste0("Event_", suffix, "_Spectrogram.png"))
spec_dst <- fs::path(ev_dir, paste0("Event_", suffix, "_Spectrum.png"))
#Assume 01 = Spectrogram, 02 = Spectrum (swap if reversed)
file_move(img1, spg_dst)
file_move(img2, spec_dst)
message(sprintf("Saved %s and %s", basename(spg_dst), basename(spec_dst)))
}
baseDir <- here('data')
DriftID<-'ADRIFT_055'
binFolder <- paste0(baseDir,'/Binaries/',DriftID)    #Folder with binaries
# this database should be a COPY of the original because we will add events to it later
db <- paste0(baseDir,'/Databases/',DriftID,' - Copy.sqlite3')
data<-readRDS(paste0(baseDir,'/AcousticStudies/',DriftID,'_Gg.rds'))
data<-readRDS(paste0(baseDir,'/AcousticStudies/',DriftID,'_Gg.rds'))
#Update known location of database and binaries for this acoustic study
data<-updateFiles(data)
GgTimes<-read.csv(here('EventTimes','ADRIFT_GgDetections.csv'))
GgTimes$start<-as.POSIXct(GgTimes$UTC,format='%Y-%m-%d %H:%M:%S',tz='UTC')
GgTimes$end<-as.POSIXct(GgTimes$end,format='%Y-%m-%d %H:%M:%S',tz='UTC')
DriftTimes<-filter(GgTimes,DriftName==DriftID)
DriftTimes$id<-paste0(DriftID,'_',seq(1:nrow(DriftTimes)))
if(substr(DriftID,1,4)=='CCES'){
DriftTimes$end<-DriftTimes$start + seconds(119) }
#Keep click detections from one channel (upper hydrophone = HTI-92-WB)
data<-filter(data, Channel==1)
#Keep click detections from one channel (upper hydrophone = HTI-92-WB)
data<-filter(data, Channel==1)
#Omit click detectors 0 and 1
data<-filter(data,detectorName!='Click_Detector_0')
data<-filter(data,detectorName!='Click_Detector_1')
data<-filter(data, peak>15 & duration<2000)
b<-1
ClickData<-getClickData(data)
#Keep subset of data for events with more than 100,000 clicks
TooBig<-ClickData %>%
group_by(eventId) %>%
summarize(TotalClicks = n()) %>%
filter(TotalClicks>100000)
set.seed(1)
KeepClicks<-ClickData %>%
filter(eventId==TooBig$eventId[b]) %>%
slice_sample(prop=0.15)
data<-data %>%
filter(!UID %in% IgnoreClicks$UID)
IgnoreClicks<-ClickData %>%
filter(eventId==TooBig$eventId[b]) %>%
slice_sample(prop=0.80)
data<-data %>%
filter(!UID %in% IgnoreClicks$UID)
#For events with large sample sizes, randomly select 80% of clicks to remove
for(b in 1:nrow(TooBig)){
set.seed(1)
IgnoreClicks<-ClickData %>%
filter(eventId==TooBig$eventId[b]) %>%
slice_sample(prop=0.80)
data<-data %>%
filter(!UID %in% IgnoreClicks$UID)
}
# fast lookup: UIDs per eventId
uid_by_event <- split(ClickData$UID, ClickData$eventId)
# if your events are already aligned 1:1 with DriftTimes rows, precompute binaries too
bin_by_event <- lapply(data@events, function(ev) ev@files[["binaries"]])
names(bin_by_event) <- DriftTimes$id   # ensure names match the ids you'll look up
db_path <- "C:/Users/annes/Documents/Github/Rissos_Geographic_Variation/data/Databases/ADRIFT_055 - Copy.sqlite3"   # <- must be a single character string
for (i in seq_len(nrow(DriftTimes))) {
id <- DriftTimes$id[i]
addPgEvent(
db_path,  # or your original PAMpal db handle variable
binary    = bin_by_event[[as.character(id)]],
UIDs      = uid_lookup[[as.character(id)]],
eventType = "Gg Click Event",
start     = DriftTimes$start[i],
end       = DriftTimes$end[i],
type      = "click"
)
}
CD <- as.data.table(ClickData)
setkey(CD, eventId)
uid_by_event <- CD[, .(UIDs = list(UID)), by = eventId]
uid_lookup <- setNames(uid_by_event$UIDs, uid_by_event$eventId)
db_path <- "C:/Users/annes/Documents/Github/Rissos_Geographic_Variation/data/Databases/ADRIFT_055 - Copy.sqlite3"   # <- must be a single character string
#For events with large sample sizes, randomly select 80% of clicks to remove
for(b in 1:nrow(TooBig)){
set.seed(1)
IgnoreClicks<-ClickData %>%
filter(eventId==TooBig$eventId[b]) %>%
slice_sample(prop=0.80)
data<-data %>%
filter(!UID %in% IgnoreClicks$UID)
ClickData<-ClickData %>%
filter(!UID %in% IgnoreClicks$UID))
#For events with large sample sizes, randomly select 80% of clicks to remove
for(b in 1:nrow(TooBig)){
set.seed(1)
IgnoreClicks<-ClickData %>%
filter(eventId==TooBig$eventId[b]) %>%
slice_sample(prop=0.80)
data<-data %>%
filter(!UID %in% IgnoreClicks$UID)
ClickData<-ClickData %>%
filter(!UID %in% IgnoreClicks$UID)
}
CD <- as.data.table(ClickData)
setkey(CD, eventId)
uid_by_event <- CD[, .(UIDs = list(UID)), by = eventId]
uid_lookup <- setNames(uid_by_event$UIDs, uid_by_event$eventId)
db_path <- "C:/Users/annes/Documents/Github/Rissos_Geographic_Variation/data/Databases/ADRIFT_055 - Copy.sqlite3"   # <- must be a single character string
for (i in seq_len(nrow(DriftTimes))) {
id <- DriftTimes$id[i]
addPgEvent(
db_path,  # or your original PAMpal db handle variable
binary    = bin_by_event[[as.character(id)]],
UIDs      = uid_lookup[[as.character(id)]],
eventType = "Gg Click Event",
start     = DriftTimes$start[i],
end       = DriftTimes$end[i],
type      = "click"
)
}
ev_dir
i<-5
i      <- event_ids[k]
event_names <- paste0(DriftID, "_Event_", str_pad(event_ids, 3, pad = "0"))
if (exists("DriftTimes")) {
event_ids <- seq_len(nrow(DriftTimes))
} else if (exists("ClickData") && "eventId" %in% names(ClickData)) {
event_ids <- sort(unique(na.omit(as.integer(ClickData$eventId))))
} else {
stop("Can't determine events: need DriftTimes or ClickData$eventId.")
}
cat(sprintf("Drift %s: %s event(s)\n", DriftID, length(event_ids)))
#Pre-create all event folders
#Pre-create all event folders
event_names <- paste0(DriftID, "_Event_", str_pad(event_ids, 3, pad = "0"))
event_dirs  <- fs::path(drift_dir, event_names)
out_root <-  file.path(baseDir,'SpectrogramsAndSpectra')
drift_dir <- fs::path(out_root, DriftID)
dir_create(drift_dir)
event_dirs  <- fs::path(drift_dir, event_names)
i      <- event_ids[k]
event_ids
k<-5
i      <- event_ids[k]
ev_dir <- event_dirs[k]
ev_tag <- event_names[k]
ev_tag
#Temp pattern with %d to capture both plots
pattern <- fs::path(ev_dir, paste0(ev_tag, "_%02d.png"))
png(filename = pattern, width = 1600, height = 1000, res = 150, bg = "white")
View(data)
i
calculateAverageSpectra(data, flim = c(0, 100000), evNum = i)
knitr::opts_chunk$set(echo = TRUE)
library("easypackages")
libraries("PAMpal","PAMmisc","dplyr","here","beepr","lubridate")
###USER-DEFINED FIELDS####
baseDir <- here('data')
DriftID<-'ADRIFT_006'
binFolder <- paste0(baseDir,'/Binaries/',DriftID)    #Folder with binaries
# this database should be the cleaned copy
db <- paste0(baseDir,'/Databases/',DriftID,' - Clean.sqlite3')
pps <- PAMpalSettings(db=db,
binaries = binFolder,
sr_hz='auto',
winLen_sec=.0025,
filterfrom_khz=10,
filterto_khz=80)
# High-pass liftering for click waveforms (magnitude-cepstrum HP lifter)
hpLifterClick <- function(
data,                     # PAMpal passes a ClickDetector data bundle here
calibration = NULL,       # keep in signature to match PAMpal's expectations
n_remove = 6,             # remove first n+1 quefrency bins incl. 0 (default 6)
return_wave = TRUE        # store filtered waveform in a list-column
) {
# data$wave: matrix [samples x channels], data$sr: sample rate
W  <- data$wave
sr <- data$sr
nC <- ncol(W)
out <- vector("list", nC)
for (ch in seq_len(nC)) {
x <- as.numeric(W[, ch])
N <- length(x)
if (!length(x) || all(!is.finite(x))) {
out[[ch]] <- list(
liftered_wave = if (return_wave) list(NA_real_) else NULL,
rms_before = NA_real_,
rms_after  = NA_real_,
lifter_n   = n_remove,
sr         = sr,
channel    = ch
)
next
}
# FFT -> log magnitude -> real cepstrum
X    <- stats::fft(x)
mag  <- Mod(X)
phs  <- Arg(X)
logS <- log(pmax(mag, .Machine$double.eps))
cep  <- Re(stats::fft(logS, inverse = TRUE)) / N
# High-pass lifter: zero 0..n_remove and their symmetric (wrapped) indices
k      <- 0:n_remove
idx_lo <- 1 + k
idx_hi <- N - k
cep[idx_lo] <- 0
cep[idx_hi] <- 0
# Rebuild log spectrum, magnitude, reapply original phase
logS_f  <- Re(stats::fft(cep))
mag_f   <- exp(logS_f)
X_f     <- mag_f * exp(1i * phs)
x_f     <- Re(stats::fft(X_f, inverse = TRUE)) / N
out[[ch]] <- list(
liftered_wave = if (return_wave) list(x_f) else NULL,
rms_before = sqrt(mean(x^2)),
rms_after  = sqrt(mean(x_f^2)),
lifter_n   = n_remove,
sr         = sr,
channel    = ch
)
}
# return one row per channel (data.frame/tibble ok)
do.call(rbind.data.frame, lapply(out, as.data.frame))
}
#Add liftering function
pps <- addFunction(pps, hpLifterClick, module = "ClickDetector", verbose = TRUE)
baseDir <- here('data')
DriftID<-'ADRIFT_055'
binFolder <- paste0(baseDir,'/Binaries/',DriftID)    #Folder with binaries
# this database should be the copy that has events added to it
db <- paste0(baseDir,'/Databases/',DriftID,' - Clean.sqlite3')
data<-readRDS(paste0(baseDir,'/AcousticStudies/',DriftID,'_Gg.rds'))
#Update known location of database and binaries for this acoustic study
data<-updateFiles(data)
# Double check warning messages
print(getWarnings(data)$message)
#Import known Risso's dolphin Event Times
GgTimes<-read.csv(here('EventTimes','ADRIFT_GgDetections.csv'))
GgTimes$start<-as.POSIXct(GgTimes$UTC,format='%Y-%m-%d %H:%M:%S',tz='UTC')
GgTimes$end<-as.POSIXct(GgTimes$end,format='%Y-%m-%d %H:%M:%S',tz='UTC')
DriftTimes<-filter(GgTimes,DriftName==DriftID)
DriftTimes$id<-paste0(DriftID,'_',seq(1:nrow(DriftTimes)))
if(substr(DriftID,1,4)=='CCES'){
DriftTimes$end<-DriftTimes$start + seconds(119) }
data<-filter(data, Channel==1)
#Omit click detectors 0 and 1
data<-filter(data,detectorName!='Click_Detector_0')
data<-filter(data,detectorName!='Click_Detector_1')
data<-filter(data, peak>15 & duration<2000)
ClickData<-getClickData(data)
#Keep subset of data for events with more than 100,000 clicks
TooBig<-ClickData %>%
group_by(eventId) %>%
summarize(TotalClicks = n()) %>%
filter(TotalClicks>100000)
#For events with large sample sizes, randomly select 80% of clicks to remove
#Take exact same sample as taken when adding events to the database
for(b in 1:nrow(TooBig)){
set.seed(1)
IgnoreClicks<-ClickData %>%
filter(eventId==TooBig$eventId[b]) %>%
slice_sample(prop=0.80)
data<-data %>%
filter(!UID %in% IgnoreClicks$UID)
ClickData<-ClickData %>%
filter(!UID %in% IgnoreClicks$UID)
}
suppressPackageStartupMessages({
library(fs)
library(stringr)
})
out_root <-  file.path(baseDir,'SpectrogramsAndSpectra')
drift_dir <- fs::path(out_root, DriftID)
dir_create(drift_dir)
#Determine event indices
if (exists("DriftTimes")) {
event_ids <- seq_len(nrow(DriftTimes))
} else if (exists("ClickData") && "eventId" %in% names(ClickData)) {
event_ids <- sort(unique(na.omit(as.integer(ClickData$eventId))))
} else {
stop("Can't determine events: need DriftTimes or ClickData$eventId.")
}
cat(sprintf("Drift %s: %s event(s)\n", DriftID, length(event_ids)))
#Pre-create all event folders
event_names <- paste0(DriftID, "_Event_", str_pad(event_ids, 3, pad = "0"))
event_dirs  <- fs::path(drift_dir, event_names)
fs::dir_create(event_dirs)
k<-5
i      <- event_ids[k]
ev_dir <- event_dirs[k]
ev_tag <- event_names[k]
pattern <- fs::path(ev_dir, paste0(ev_tag, "_%02d.png"))
png(filename = pattern, width = 1600, height = 1000, res = 150, bg = "white")
calculateAverageSpectra(data, flim = c(0, 100000), evNum = i)
dev.off()
#Paths for the auto-saved plots
img1 <- fs::path(ev_dir, paste0(ev_tag, "_01.png"))
img2 <- fs::path(ev_dir, paste0(ev_tag, "_02.png"))
#Desired names: Spectrogram_XXX.png and Spectrum_XXX.png
suffix <- str_pad(i, 3, pad = "0")
spg_dst  <- fs::path(ev_dir, paste0("Event_", suffix, "_Spectrogram.png"))
spec_dst <- fs::path(ev_dir, paste0("Event_", suffix, "_Spectrum.png"))
#Assume 01 = Spectrogram, 02 = Spectrum (swap if reversed)
file_move(img1, spg_dst)
file_move(img2, spec_dst)
k=6
i      <- event_ids[k]
ev_dir <- event_dirs[k]
ev_tag <- event_names[k]
#Temp pattern with %d to capture both plots
pattern <- fs::path(ev_dir, paste0(ev_tag, "_%02d.png"))
png(filename = pattern, width = 1600, height = 1000, res = 150, bg = "white")
calculateAverageSpectra(data, flim = c(0, 100000), evNum = i)
i      <- event_ids[k]
ev_dir <- event_dirs[k]
ev_tag <- event_names[k]
#Temp pattern with %d to capture both plots
pattern <- fs::path(ev_dir, paste0(ev_tag, "_%02d.png"))
png(filename = pattern, width = 1600, height = 1000, res = 150, bg = "white")
calculateAverageSpectra(data, flim = c(0, 100000), evNum = i)
dev.off()
#Paths for the auto-saved plots
img1 <- fs::path(ev_dir, paste0(ev_tag, "_01.png"))
img2 <- fs::path(ev_dir, paste0(ev_tag, "_02.png"))
#Desired names: Spectrogram_XXX.png and Spectrum_XXX.png
suffix <- str_pad(i, 3, pad = "0")
spg_dst  <- fs::path(ev_dir, paste0("Event_", suffix, "_Spectrogram.png"))
spec_dst <- fs::path(ev_dir, paste0("Event_", suffix, "_Spectrum.png"))
#Assume 01 = Spectrogram, 02 = Spectrum (swap if reversed)
file_move(img1, spg_dst)
file_move(img2, spec_dst)
message(sprintf("Saved %s and %s", basename(spg_dst), basename(spec_dst)))
